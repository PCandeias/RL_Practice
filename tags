!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.9~svn20110310	//
A2CAgent	agents/a2c_agent.py	/^class A2CAgent(Agent):$/;"	c
Agent	agents/agent.py	/^class Agent(object):$/;"	c
AtariPreprocessing	wrappers/atari_preprocessing.py	/^class AtariPreprocessing(gym.Wrapper):$/;"	c
CNNA2CAgent	agents/a2c_agent.py	/^class CNNA2CAgent(A2CAgent):$/;"	c
CNNDQNAgent	agents/dqn_agent.py	/^class CNNDQNAgent(DQNAgent):$/;"	c
DQNAgent	agents/dqn_agent.py	/^class DQNAgent(object):$/;"	c
PriorityReplayBuffer	utility/random_buffer.py	/^class PriorityReplayBuffer(ReplayBuffer):$/;"	c
ReplayBuffer	utility/random_buffer.py	/^class ReplayBuffer(object):$/;"	c
StackObservation	wrappers/stackobservation.py	/^class StackObservation(gym.Wrapper):$/;"	c
TimeLimit	wrappers/timelimit.py	/^class TimeLimit(gym.Wrapper):$/;"	c
__all__	wrappers/__init__.py	/^__all__ = [ basename(f)[:-3] for f in modules if isfile(f) and not f.endswith('__init__.py')]$/;"	v
__getitem__	utility/random_buffer.py	/^    def __getitem__(self, index):$/;"	m	class:ReplayBuffer	file:
__init__	agents/a2c_agent.py	/^    def __init__(self, $/;"	m	class:A2CAgent
__init__	agents/a2c_agent.py	/^    def __init__(self, *args, **kwargs):$/;"	m	class:CNNA2CAgent
__init__	agents/agent.py	/^    def __init__(self, $/;"	m	class:Agent
__init__	agents/dqn_agent.py	/^    def __init__(self, $/;"	m	class:DQNAgent
__init__	agents/dqn_agent.py	/^    def __init__(self, *args, **kwargs):$/;"	m	class:CNNDQNAgent
__init__	utility/random_buffer.py	/^    def __init__(self, max_len):$/;"	m	class:PriorityReplayBuffer
__init__	utility/random_buffer.py	/^    def __init__(self, max_len):$/;"	m	class:ReplayBuffer
__init__	wrappers/atari_preprocessing.py	/^    def __init__(self, env):$/;"	m	class:AtariPreprocessing
__init__	wrappers/stackobservation.py	/^    def __init__(self, env, stack_size):$/;"	m	class:StackObservation
__init__	wrappers/timelimit.py	/^    def __init__(self, env, max_steps):$/;"	m	class:TimeLimit
__len__	utility/random_buffer.py	/^    def __len__(self):$/;"	m	class:ReplayBuffer	file:
__preprocessing	wrappers/atari_preprocessing.py	/^    def __preprocessing(self, observation):$/;"	m	class:AtariPreprocessing	file:
_build_actor_model	agents/a2c_agent.py	/^    def _build_actor_model(self, alpha=0.01):$/;"	m	class:A2CAgent
_build_critic_model	agents/a2c_agent.py	/^    def _build_critic_model(self, alpha=0.01):$/;"	m	class:A2CAgent
_build_critic_model	agents/a2c_agent.py	/^    def _build_critic_model(self, alpha=0.01):$/;"	m	class:CNNA2CAgent
_build_model	agents/dqn_agent.py	/^    def _build_model(self, alpha=0.01):$/;"	m	class:CNNDQNAgent
_build_model	agents/dqn_agent.py	/^    def _build_model(self, alpha=0.01):$/;"	m	class:DQNAgent
_get_predictions	agents/a2c_agent.py	/^    def _get_predictions(self, observation):$/;"	m	class:A2CAgent
_get_predictions	agents/dqn_agent.py	/^    def _get_predictions(self, observation):$/;"	m	class:DQNAgent
_load_model	agents/a2c_agent.py	/^    def _load_model(self, load_filename):$/;"	m	class:A2CAgent
_load_model	agents/dqn_agent.py	/^    def _load_model(self, load_filename):$/;"	m	class:DQNAgent
_propagate	utility/random_buffer.py	/^    def _propagate(self, s_idx, dif):$/;"	m	class:PriorityReplayBuffer
_retrieve	utility/random_buffer.py	/^    def _retrieve(self, s_idx, val):$/;"	m	class:PriorityReplayBuffer
_save_model	agents/a2c_agent.py	/^    def _save_model(self, save_filename):$/;"	m	class:A2CAgent
_save_model	agents/dqn_agent.py	/^    def _save_model(self, save_filename):$/;"	m	class:DQNAgent
_select_action	agents/a2c_agent.py	/^    def _select_action(self, observation):$/;"	m	class:A2CAgent
_select_action	agents/agent.py	/^    def _select_action(self, observation):$/;"	m	class:Agent
_select_action	agents/dqn_agent.py	/^    def _select_action(self, observation, eps=None):$/;"	m	class:DQNAgent
_store_transition	agents/agent.py	/^    def _store_transition(self, state, action, reward, next_state, done):$/;"	m	class:Agent
_store_transition	agents/dqn_agent.py	/^    def _store_transition(self, state, action, reward, next_state, done):$/;"	m	class:DQNAgent
_train_step	agents/a2c_agent.py	/^    def _train_step(self):$/;"	m	class:A2CAgent
_train_step	agents/agent.py	/^    def _train_step(self):$/;"	m	class:Agent
_train_step	agents/dqn_agent.py	/^    def _train_step(self):$/;"	m	class:DQNAgent
a	test.py	/^            a = agent.step(reward, np.ones(1) * val)$/;"	v
a	test.py	/^    a = agent.begin_episode(np.ones(1) * 0)$/;"	v
action	gym_lunar.py	/^            action = agent.step(reward, obs)$/;"	v
action	gym_lunar.py	/^    action = agent.begin_episode(obs)$/;"	v
action	gym_pole.py	/^            action = agent.step(reward, obs)$/;"	v
action	gym_pole.py	/^    action = agent.begin_episode(obs)$/;"	v
action	gym_runner.py	/^            action = agent.step(reward, obs)$/;"	v
action	gym_runner.py	/^    action = agent.begin_episode(obs)$/;"	v
action	pong_runner.py	/^            action = agent.step(reward, obs)$/;"	v
action	pong_runner.py	/^    action = agent.begin_episode(obs)$/;"	v
agent	gym_lunar.py	/^agent = A2CAgent(8, 4, c_alpha=0.0025, a_alpha=0.0005, memory_size=10000, min_history_size=1000, gamma=0.99)$/;"	v
agent	gym_lunar.py	/^agent = DQNAgent(8, 4, alpha=0.00025, memory_size=10000, min_history_size=1000, gamma=0.99)$/;"	v
agent	gym_pole.py	/^agent = A2CAgent(4, 2, memory_size=10000, min_history_size=100, c_alpha=0.0025, a_alpha=0.0005, priority_replay=True)$/;"	v
agent	gym_pole.py	/^agent = DQNAgent(4, 2, memory_size=10000, eps_decay_steps=10000, min_history_size=100, alpha=.00025)$/;"	v
agent	gym_runner.py	/^agent = DQNAgent(2, 3, priority_replay=False)$/;"	v
agent	pong_runner.py	/^agent = CNNDQNAgent(env.observation_space.shape, env.action_space.n, priority_replay=False, eps_decay_steps=100000,$/;"	v
agent	test.py	/^agent = DQNAgent(1,9, decay_steps=20000)$/;"	v
append	utility/random_buffer.py	/^    def append(self, element):$/;"	m	class:PriorityReplayBuffer
append	utility/random_buffer.py	/^    def append(self, element):$/;"	m	class:ReplayBuffer
begin_episode	agents/agent.py	/^    def begin_episode(self, observation):$/;"	m	class:Agent
begin_episode	agents/dqn_agent.py	/^    def begin_episode(self, observation):$/;"	m	class:DQNAgent
copy_model	utility/utility.py	/^def copy_model(model):$/;"	f
cur_it	test.py	/^    cur_it = 0$/;"	v
done	gym_lunar.py	/^    done = False$/;"	v
done	gym_pole.py	/^    done = False$/;"	v
done	gym_runner.py	/^    done = False$/;"	v
done	pong_runner.py	/^    done = False$/;"	v
end_episode	agents/agent.py	/^    def end_episode(self, reward):$/;"	m	class:Agent
end_episode	agents/dqn_agent.py	/^    def end_episode(self, reward):$/;"	m	class:DQNAgent
env	gym_lunar.py	/^env = gym.make('LunarLander-v2')$/;"	v
env	gym_pole.py	/^env = TimeLimit(env, 200)$/;"	v
env	gym_pole.py	/^env = gym.make('CartPole-v1')$/;"	v
env	gym_runner.py	/^env = gym.make('MountainCar-v0')$/;"	v
env	pong_runner.py	/^env = AtariPreprocessing(env)$/;"	v
env	pong_runner.py	/^env = StackObservation(env, 4)$/;"	v
env	pong_runner.py	/^env = gym.make('Pong-v0')$/;"	v
file_exists	utility/utility.py	/^def file_exists(filename):$/;"	f
l_rewards	gym_lunar.py	/^l_rewards = deque(maxlen=100)$/;"	v
l_rewards	gym_pole.py	/^l_rewards = deque(maxlen=100)$/;"	v
l_rewards	gym_runner.py	/^l_rewards = deque(maxlen=100)$/;"	v
l_rewards	pong_runner.py	/^l_rewards = deque(maxlen=100)$/;"	v
modules	wrappers/__init__.py	/^modules = glob.glob(dirname(__file__)+"\/*.py")$/;"	v
n_episodes	gym_lunar.py	/^n_episodes = 10000$/;"	v
n_episodes	gym_pole.py	/^n_episodes = 20000$/;"	v
n_episodes	gym_runner.py	/^n_episodes = 20000$/;"	v
n_episodes	pong_runner.py	/^n_episodes = 100000$/;"	v
obs	gym_lunar.py	/^    obs = env.reset()$/;"	v
obs	gym_pole.py	/^    obs = env.reset()$/;"	v
obs	gym_runner.py	/^    obs = env.reset()$/;"	v
obs	pong_runner.py	/^    obs = env.reset()$/;"	v
render	gym_lunar.py	/^render = False$/;"	v
render	gym_pole.py	/^render = False$/;"	v
render	gym_runner.py	/^render = False$/;"	v
render	pong_runner.py	/^render = False$/;"	v
reset	wrappers/atari_preprocessing.py	/^    def reset(self):$/;"	m	class:AtariPreprocessing
reset	wrappers/stackobservation.py	/^    def reset(self):$/;"	m	class:StackObservation
reset	wrappers/timelimit.py	/^    def reset(self):$/;"	m	class:TimeLimit
sample	utility/random_buffer.py	/^    def sample(self, n_samples):$/;"	m	class:PriorityReplayBuffer
sample	utility/random_buffer.py	/^    def sample(self, n_samples):$/;"	m	class:ReplayBuffer
step	agents/agent.py	/^    def step(self, reward, observation):$/;"	m	class:Agent
step	agents/dqn_agent.py	/^    def step(self, reward, observation):$/;"	m	class:DQNAgent
step	wrappers/atari_preprocessing.py	/^    def step(self, action):$/;"	m	class:AtariPreprocessing
step	wrappers/stackobservation.py	/^    def step(self, action):$/;"	m	class:StackObservation
step	wrappers/timelimit.py	/^    def step(self, action):$/;"	m	class:TimeLimit
total_reward	gym_lunar.py	/^    total_reward = 0$/;"	v
total_reward	gym_pole.py	/^    total_reward = 0$/;"	v
total_reward	gym_runner.py	/^    total_reward = 0$/;"	v
total_reward	pong_runner.py	/^    total_reward = 0$/;"	v
total_weight	utility/random_buffer.py	/^    def total_weight(self):$/;"	m	class:PriorityReplayBuffer
update	utility/random_buffer.py	/^    def update(self, idx, p):$/;"	m	class:PriorityReplayBuffer
val	test.py	/^            val = np.random.randint(0,9)$/;"	v
val	test.py	/^    val = np.random.randint(0,9)$/;"	v
